<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />

    <!--<title>Jongpil Lee - Music and Deep Learning Blog</title>-->
    
      <title>Jongpil Lee - Music and Deep Learning Blog</title>
    
    
    
      <meta name="description" content= "Jongpil Lee Blog: Music Information Retrieval, Deep Learning" >
    
    
    <!--<meta name="description" content="Jongpil Lee Blog: Music Information Retrieval, Deep Learning" />-->

    <meta name="HandheldFriendly" content="True" />
    <meta name="MobileOptimized" content="320" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="stylesheet" type="text/css" href="/assets/css/screen.css" />
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400" />
    <!-- Customisation  -->
    <link rel="stylesheet" type="text/css" href="/assets/css/main.css" />
    <link rel="icon" type="image/png" href="/favicon.png">

</head>
<body class="home-template">

    <div id="fb-root"></div>
    <script>(function(d, s, id) {
      var js, fjs = d.getElementsByTagName(s)[0];
      if (d.getElementById(id)) return;
      js = d.createElement(s); js.id = id;
      js.src = "//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v2.9&appId=1775107236113302";
      fjs.parentNode.insertBefore(js, fjs);
    }(document, 'script', 'facebook-jssdk'));</script>

    <nav class="main-nav clearfix">
    <a class="back-button icon-arrow-left" href="/">Home</a>
    <a class="subscribe-button icon-feed" href="/feed.xml">Subscribe</a>
</nav>


<main class="content" role="main">
    <article class="post">
        <!-- <header class="post-header">
            <a id="blog-logo" href="/">
                
                    <span class="blog-title">Jongpil Lee</span>
                
            </a>
        </header> -->

        <h1 class="post-title">About me</h1>

        <section class="post-content">
            <p><br />
<br />
<strong>Research Interests</strong></p>

<ul>
  <li>Music Information Retrieval</li>
  <li>Deep Learning</li>
</ul>

<p><br />
<strong>Career</strong></p>

<ul>
  <li><font color="black">2020 - now</font>. CEO (Co-founder), <h4><a class="one" href="https://www.neutune.com/" target="_blank">Neutune</a></h4>, Seoul, South Korea</li>
</ul>

<p><br />
<strong>Education</strong></p>

<ul>
  <li><font color="black">2017 - 2021</font>. PhD (<h4><a class="one" href="assets/images/Jongpil_KAIST_PhD_thesis.pdf" target="_blank">PhD Thesis</a></h4>), Graduate School of Culture Technology, KAIST, Daejeon, South Korea (Advisor: <h4><a class="one" href="http://mac.kaist.ac.kr/~juhan/?" target="_blank">Juhan Nam</a></h4>)</li> 
  <li><font color="black">2015 - 2017</font>. MS, Graduate School of Culture Technology, KAIST, Daejeon, South Korea</li>
  <li><font color="black">2007 - 2015</font>. BS, EE, Hanyang University, Seoul, South Korea</li>
</ul>

<p><br />
<strong>Experience</strong></p>

<ul>
  <li><font color="black">2020</font>. Visiting PhD, Music and Audio Research Laboratory, New York University, New York City, United States</li>
</ul>

<ul>
  <li><font color="black">2019</font>. Research Intern, Audio Research Group, Adobe, San Francisco, United States</li>
</ul>

<ul>
  <li><font color="black">2017</font>. Research Intern, Clova Artificial Intelligence Research, Naver, Seongnam, South Korea</li>
</ul>

<p><br />
<strong>Tutorial</strong></p>

<p>	
	<h4>
		<a class="one" href="https://www.ismir2020.net/tutorials/" target="_blank">Metric Learning for Music Information Retrieval</a>
	</h4>
	Brian McFee, <strong>Jongpil Lee</strong>, and Juhan Nam<br />
	<i>International Society of Music Information Retrieval Conference (ISMIR), 2020</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="https://ismir2019.ewi.tudelft.nl/?q=tutorials" target="_blank">Waveform-based Music Processing with Deep Learning</a> 
	</h4>
	Jordi Pons, <strong>Jongpil Lee</strong>, and Sander Dieleman<br />
	<i>International Society of Music Information Retrieval Conference (ISMIR), 2019</i> <br /> 
</p>

<p><br />
<strong>Journals</strong></p>

<p>	
	<h4>
		<a class="one" href="assets/images/taslp2020_singing_tag.pdf" target="_blank">Semantic Tagging of Singing Voices in Popular Music Recordings</a>
	</h4>
	Keunhyoung Luke Kim, <strong>Jongpil Lee</strong>, Sangeun Kum, Chae Lin Park, and Juhan Nam<br />
	<i>IEEE/ACM Transactions on Audio, Speech and Language Processing, 2020</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="https://ieeexplore.ieee.org/document/8681654" target="_blank">Comparison and Analysis of SampleCNN Architectures for Audio Classification</a>
	</h4>
	Taejun Kim, <strong>Jongpil Lee</strong>, and Juhan Nam<br />
	<i>IEEE Journal of Selected Topics in Signal Processing, 2019</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="https://ieeexplore.ieee.org/document/8588424" target="_blank">Deep Learning for Audio-based Music Classification and Tagging: Teaching Computers to Distinguish Rock from Bach</a>  
	</h4>
	Juhan Nam, Keunwoo Choi, <strong>Jongpil Lee</strong>, Szu-Yu Chou, and Yi-Hsuan Yang<br />
	<i>IEEE Signal Processing Magazine, 2019</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="http://www.mdpi.com/2076-3417/8/1/150" target="_blank">SampleCNN: End-to-End Deep Convolutional Neural Networks Using Very Small Filters for Music Classification</a> 
	</h4>
	<strong>Jongpil Lee</strong>, Jiyoung Park, Keunhyoung Luke Kim, and Juhan Nam<br />
	<i>Applied Sciences, 2018</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="http://ieeexplore.ieee.org/document/7944704/" target="_blank">Multi-Level and Multi-Scale Feature Aggregation Using Pre-trained Convolutional Neural Networks for Music Auto-tagging</a>
	</h4>
	<strong>Jongpil Lee</strong>, and Juhan Nam<br />
	<i>IEEE Signal Processing Letters, 2017</i> <br /> 
</p>

<p><br />
<strong>Exhibition</strong></p>

<p>	
	<h4>
		NEUROSCAPE: Artificial Soundscape Based on Multimodal Connections of Deep Neural Networks 
	</h4>
	Seungsoon Park, <strong>Jongpil Lee</strong>, and Juhan Nam<br />
	<i>International Computer Music Conference (ICMC), 2018</i> <br /> 
</p>

<p><br />
<strong>Conferences, Workshops, Challenges, Demos</strong></p>

<p>	
	<h4>
		Learning a Cross-domain Embedding Space of Vocal and Mixed Audio with a Structure-preserving Triplet Loss
	</h4>
	Keunhyoung Luke Kim, <strong>Jongpil Lee</strong>, Sangeun Kum, and Juhan Nam<br />
	<i>International Society of Music Information Retrieval Conference (ISMIR), 2021</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="assets/images/icmc2021_mixedscape.pdf" target="_blank">Mixed Scape: Development of Framework and Artwork for Auditory Correspondence in Mixed Reality</a>
	</h4>
	Seungsoon Park, <strong>Jongpil Lee</strong>, Taewan Kim, Tae Hong Park, Joonhyung Bae, and Juhan Nam<br />
	<i>International Computer Music Conference (ICMC), 2021</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="https://arxiv.org/abs/2008.03729" target="_blank">Metric Learning VS Classification for Disentangled Music Representation Learning</a>
	</h4>
	<strong>Jongpil Lee</strong>, Nicholas J. Bryan, Justin Salamon, Zeyu Jin, and Juhan Nam<br />
	<i>International Society of Music Information Retrieval Conference (ISMIR), 2020</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="https://arxiv.org/abs/2008.01190" target="_blank">Musical Word Embedding: Bridging the Gap between Listening Contexts and Music</a>
	</h4>
	Seungheon Doh, <strong>Jongpil Lee</strong>, Tae Hong Park, and Juhan Nam<br />
	<i>Machine Learning for Media Discovery Workshop, International Conference on Machine Learning (ICML), 2020 (accepted)</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="https://ieeexplore.ieee.org/document/9053442" target="_blank">Disentangled Multidimensional Metric Learning for Music Similarity</a>
	</h4>
	<strong>Jongpil Lee</strong>, Nicholas J. Bryan, Justin Salamon, Zeyu Jin, and Juhan Nam<br />
	<i>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2020</i> <br /> 
	<i> *** IEEE SPS Student Travel Grant ***</i>
</p>

<p>	
	<h4>
		<a class="one" href="https://arxiv.org/abs/1907.02670" target="_blank">Zero-shot Learning for Audio-based Music Classification and Tagging</a>
	</h4>
	Jeong Choi*, <strong>Jongpil Lee*</strong>, Jiyoung Park, and Juhan Nam<br />
	<i>International Society of Music Information Retrieval Conference (ISMIR), 2019</i> <br /> 
	<i> * Equally contributed</i>
</p>

<p>	
	<h4>
		<a class="one" href="http://archives.ismir.net/ismir2019/paper/000050.pdf" target="_blank">A Cross-Scape Plot Representation for Visualizing Symbolic Melodic Similarity</a>
	</h4>
	Saebyul Park, Taegyun Kwon, <strong>Jongpil Lee</strong>, Jeounghoon Kim, and Juhan Nam<br />
	<i>International Society of Music Information Retrieval Conference (ISMIR), 2019</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="https://arxiv.org/abs/1906.11783" target="_blank">Representation Learning of Music Using Artist, Album, and Track Information</a>
	</h4>
	<strong>Jongpil Lee</strong>, Jiyoung Park, and Juhan Nam<br />
	<i>Machine Learning for Music Discovery Workshop, International Conference on Machine Learning (ICML), 2019</i> 
</p>

<p>	
	<h4>
		<a class="one" href="https://arxiv.org/abs/1906.08615" target="_blank">Zero-shot Learning and Knowledge Transfer in Music Classification and Tagging</a>
	</h4>
	Jeong Choi, <strong>Jongpil Lee</strong>, Jiyoung Park, and Juhan Nam<br />
	<i>Machine Learning for Music Discovery Workshop, International Conference on Machine Learning (ICML), 2019</i> 
</p>

<p>	
	<h4>
		<a class="one" href="https://arxiv.org/abs/1807.06786" target="_blank">Deep Content-User Embedding Model for Music Recommendation</a> 
	</h4>
	<strong>Jongpil Lee</strong>, Kyungyun Lee, Jiyoung Park, Jangyeon Park, and Juhan Nam<br />
	<i>https://arxiv.org/abs/1807.06786, 2018</i> 
</p>

<p>	
	<h4>
		<a class="one" href="https://arxiv.org/abs/1710.06648" target="_blank">Representation Learning of Music Using Artist Labels</a> 
	</h4>
	Jiyoung Park*, <strong>Jongpil Lee*</strong>, Jangyeon Park, Jung-Woo Ha, and Juhan Nam<br />
	<i>International Society of Music Information Retrieval Conference (ISMIR), 2018</i> <br /> 
	<i> * Equally contributed</i>
</p>

<p>	
	<h4>
		<a class="one" href="https://arxiv.org/abs/1807.09208" target="_blank">A Hybrid of Deep Audio Feature and i-vector for Artist Recognition</a> 
	</h4>
	Jiyoung Park, Donghyun Kim, <strong>Jongpil Lee</strong>, Sangeun Kum, and Juhan Nam<br />
	<i>Joint Workshop on Machine Learning for Music, International Conference on Machine Learning (ICML), 2018</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="https://arxiv.org/abs/1710.10451" target="_blank">Sample-level CNN Architectures for Music Auto-tagging Using Raw Waveforms</a> 
	</h4>
	Taejun Kim, <strong>Jongpil Lee</strong>, and Juhan Nam<br />
	<i>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2018</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="https://arxiv.org/abs/1712.00866" target="_blank">Raw Waveform-based Audio Classification Using Sample-level CNN Architectures</a>
	</h4>
	<strong>Jongpil Lee</strong>, Taejun Kim, Jiyoung Park, and Juhan Nam<br />
	<i>Machine Learning for Audio Signal Processing Workshop, Neural Information Processing Systems (NIPS), 2017</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="https://ismir2017.smcnus.org/lbds/Kim2017a.pdf" target="_blank">Building K-POP Singing Voice Tag Dataset: A Progress Report</a> 
	</h4>
	KeunHyoung Luke Kim, Sangeun Kum, Chae Lin Park, <strong>Jongpil Lee</strong>, Jiyoung Park, and Juhan Nam<br />
	<i>Late-Breaking/Demo Session of International Society of Music Information Retrieval Conference (ISMIR), 2017</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="https://ismir2017.smcnus.org/lbds/Suh2017.pdf" target="_blank">MUSIC GALAXY HITCHHIKER: 3D Web Music Navigation Through Audio Space Trained with Tag and Artist Labels</a> 
	</h4>
	Dongwoo Suh, Kyungyun Lee, <strong>Jongpil Lee</strong>, Jiyoung Park, and Juhan Nam<br />
	<i>Late-Breaking/Demo Session of International Society of Music Information Retrieval Conference (ISMIR), 2017</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="http://www.music-ir.org/mirex/abstracts/2017/LPNKK1.pdf" target="_blank">Cross-cultural Transfer Learning Using Sample-level Deep Convolutional Neural Networks</a> 
	</h4>
	<strong>Jongpil Lee</strong>, Jiyoung Park, Chanju Kim, Adrian Kim, Jangyeon Park, Jung-Woo Ha, and Juhan Nam<br />
	<i>Music Information Retrieval Evaluation eXchange (MIREX), 2017</i><br />
	<i>1st place in the four K-POP tasks across all algorithms submitted so far</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="http://www.music-ir.org/mirex/abstracts/2017/PLNPH1.pdf" target="_blank">Representation Learning Using Artist labels for Audio Classification Tasks</a> 
	</h4>
	Jiyoung Park, <strong>Jongpil Lee</strong>, Jangyeon Park, Jung-Woo Ha, and Juhan Nam<br />
	<i>Music Information Retrieval Evaluation eXchange (MIREX), 2017</i><br />
	<i>1st place in the Music Mood Classification task across all algorithms submitted so far</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="http://www.cs.tut.fi/sgn/arg/dcase2017/documents/challenge_technical_reports/DCASE2017_Lee_118.pdf" target="_blank">Combining Multi-Scale Features Using Sample-level Deep Convolutional Neural Networks for Weakly Supervised Sound Event Detection</a> 
	</h4>
	<strong>Jongpil Lee</strong>, Jiyoung Park, Sangeun Kum, Youngho Jeong, and Juhan Nam<br />
	<i>Proceedings of the 2nd Workshop on Detection and Classification of Acoustic Scenes and Events (DCASE), 2017</i> <br /> 
</p>

<p>	
	<h4>
		<a class="one" href="https://arxiv.org/abs/1706.06810" target="_blank">Multi-Level and Multi-Scale Feature Aggregation Using Sample-level Deep Convolutional Neural Networks for Music Classification</a>
	</h4>
	<strong>Jongpil Lee</strong>, and Juhan Nam<br />
	<i>Machine Learning for Music Discovery Workshop, International Conference on Machine Learning (ICML), 2017</i> <br /> 
</p>

<p>	
	<h4>
	<a class="one" href="https://arxiv.org/abs/1703.01789" target="_blank">Sample-level Deep Convolutional Neural Networks for Music Auto-tagging Using Raw Waveforms</a>
	</h4>
	<strong>Jongpil Lee</strong>, Jiyoung Park, Keunhyoung Luke Kim, and Juhan Nam<br />
	<i>Sound and Music Computing Confenrence (SMC), 2017</i> <br />
</p>

<p>	
	<h4>
		<a class="one" href="assets/images/The effect of DJ's social networks on music popularity.pdf" target="_blank">The Effect of DJs’ Social Network on Music Popularity</a>
	</h4>
	Hyeongseok Wi, Kyung hoon Hyun, <strong>Jongpil Lee</strong>, and Wonjae Lee<br />
	<i>International Computer Music Conference (ICMC), 2016</i> <br /> 
</p>

<p><br />
<strong>Contact</strong></p>

<ul>
  <li>jongpillee.brian (at) gmail.com</li>
  <li>richter (at) kaist.ac.kr</li>
</ul>

<p><span class="image left">
			<img src="assets/images/profile.png" title="profile" />
		</span></p>

        </section>

    </article>

</main>

    <footer class="site-footer clearfix">
      <section class="copyright">
        <a href="/">Jongpil Lee</a> &copy; 
               &bull; All rights reserved.
      </section>
      <section class="poweredby">Made with Jekyll using 
        <a href="http://github.com/rosario/kasper">Kasper theme</a>
      </section>
    </footer>
    
    <script type="text/javascript" src="/assets/js/jquery-1.11.1.min.js"></script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="/assets/js/index.js"></script>

    <!-- Google Analytics Tracking code -->
    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-XXXXXXXX-X']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();


    </script>   
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-101334039-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
